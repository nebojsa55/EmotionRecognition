{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from sklearn.metrics import accuracy_score, f1_score\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "import catboost\r\n",
    "from catboost import EShapCalcType, EFeaturesSelectionAlgorithm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "features = pd.read_csv('all_features.csv', index_col=0)\r\n",
    "targets = pd.read_csv('za_klasifikaciju.csv', index_col=0)\r\n",
    "\r\n",
    "targets = targets[['Valence', 'Arousal', 'Dominance', 'Liking']]\r\n",
    "targets[targets < 4.5] = 0\r\n",
    "targets[targets >= 4.5] = 1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "features.isna().sum().sum()\r\n",
    "features.fillna(0, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features, targets['Valence'], test_size=0.3)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "len(features.columns)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1489"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "def find_n_best(features, c, n_features=50):\r\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features, targets[c], test_size=0.3)\r\n",
    "\r\n",
    "    train_pool = catboost.Pool(data=x_train, label=y_train)\r\n",
    "    test_pool = catboost.Pool(data=x_test, label=y_test)\r\n",
    "\r\n",
    "    cat_params = {\r\n",
    "        'loss_function':'Logloss',\r\n",
    "        'eval_metric':'F1',\r\n",
    "        'learning_rate':0.001,\r\n",
    "        'depth':5,\r\n",
    "        'subsample': 0.8\r\n",
    "    }\r\n",
    "\r\n",
    "    model = catboost.CatBoostClassifier(\r\n",
    "        num_boost_round=5000,\r\n",
    "        early_stopping_rounds=15\r\n",
    "    )\r\n",
    "\r\n",
    "\r\n",
    "    summary = model.select_features(\r\n",
    "        train_pool,\r\n",
    "        eval_set=test_pool,\r\n",
    "        features_for_select='0-1488',\r\n",
    "        num_features_to_select=50,\r\n",
    "        steps=3,\r\n",
    "        algorithm=EFeaturesSelectionAlgorithm.RecursiveByShapValues,\r\n",
    "        shap_calc_type=EShapCalcType.Regular,\r\n",
    "        train_final_model=True,\r\n",
    "        logging_level='Silent',\r\n",
    "        plot=False\r\n",
    "    )\r\n",
    "    return summary['selected_features_names']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "summary.keys()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dict_keys(['selected_features', 'eliminated_features_names', 'eliminated_features', 'selected_features_names'])"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "cat_params = {\r\n",
    "    'loss_function':'Logloss',\r\n",
    "    'eval_metric':'F1',\r\n",
    "    'learning_rate':0.001,\r\n",
    "    'depth':5,\r\n",
    "    'subsample': 0.8\r\n",
    "}\r\n",
    "\r\n",
    "for c in ['Valence', 'Arousal', 'Dominance', 'Liking']:\r\n",
    "\r\n",
    "    feats_c = find_n_best(features, c, 200)\r\n",
    "    cat_crossval = catboost.Pool(data=features[feats_c], label=targets[c])\r\n",
    "\r\n",
    "    cat_cv = catboost.cv(pool=cat_crossval,\r\n",
    "                        params=cat_params,\r\n",
    "                        num_boost_round=5000,\r\n",
    "                        nfold=10,\r\n",
    "                        verbose_eval=0,\r\n",
    "                        early_stopping_rounds=15\r\n",
    "                        )\r\n",
    "    ind_max = np.argmax(cat_cv['test-F1-mean'])\r\n",
    "    print(f'{c}: test F1 mean = {cat_cv.loc[ind_max, \"test-F1-mean\"]}, std = {cat_cv.loc[ind_max, \"test-F1-std\"]}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Stopped by overfitting detector  (15 iterations wait)\n",
      "Valence: test F1 mean = 0.775064817587701, std = 0.002949963887987618\n",
      "Stopped by overfitting detector  (15 iterations wait)\n",
      "Arousal: test F1 mean = 0.779790896307484, std = 0.0015909335084335135\n",
      "Stopped by overfitting detector  (15 iterations wait)\n",
      "Dominance: test F1 mean = 0.8035778943302516, std = 0.0038008260569480953\n",
      "Stopped by overfitting detector  (15 iterations wait)\n",
      "Liking: test F1 mean = 0.8210360129714968, std = 0.001601198792484367\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "cat_params = {\r\n",
    "    'loss_function':'Logloss',\r\n",
    "    'eval_metric':'Accuracy',\r\n",
    "    'learning_rate':0.001,\r\n",
    "    'depth':5,\r\n",
    "    'subsample': 0.8\r\n",
    "}\r\n",
    "\r\n",
    "for c in ['Valence', 'Arousal', 'Dominance', 'Liking']:\r\n",
    "\r\n",
    "    feats_c = find_n_best(features, c, 200)\r\n",
    "    cat_crossval = catboost.Pool(data=features[feats_c], label=targets[c])\r\n",
    "\r\n",
    "    cat_cv = catboost.cv(pool=cat_crossval,\r\n",
    "                        params=cat_params,\r\n",
    "                        num_boost_round=5000,\r\n",
    "                        nfold=10,\r\n",
    "                        verbose_eval=0,\r\n",
    "                        early_stopping_rounds=15\r\n",
    "                        )\r\n",
    "    ind_max = np.argmax(cat_cv['test-Accuracy-mean'])\r\n",
    "    print(f'{c}: test Accuracy mean = {cat_cv.loc[ind_max, \"test-Accuracy-mean\"]}, std = {cat_cv.loc[ind_max, \"test-Accuracy-std\"]}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Custom logger is already specified. Specify more than one logger at same time is not thread safe."
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Stopped by overfitting detector  (15 iterations wait)\n",
      "Valence: test Accuracy mean = 0.6328156473173412, std = 0.004557253919327737\n",
      "Stopped by overfitting detector  (15 iterations wait)\n",
      "Arousal: test Accuracy mean = 0.6421970850119025, std = 0.010403661531627728\n",
      "Stopped by overfitting detector  (15 iterations wait)\n",
      "Dominance: test Accuracy mean = 0.6718528257187326, std = 0.008005929215926811\n",
      "Stopped by overfitting detector  (15 iterations wait)\n",
      "Liking: test Accuracy mean = 0.6953125, std = 0.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit"
  },
  "interpreter": {
   "hash": "1c08fbfe57ae6755a1ca5884fd5e3be2f7f12a42ce6bb14b1db8b131357451c6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}